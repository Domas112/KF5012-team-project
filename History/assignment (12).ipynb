{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import PIL\nimport numpy as np # linear algebra\nfrom numpy import asarray\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os, os.path\n\nfrom keras.applications import ResNet152\n\nimport matplotlib.pyplot as plt\n\n#image preprocessing libraries\nimport skimage\nfrom skimage import io\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\n\n#import needed for augmentation\n%reload_ext autoreload\n%autoreload 2\n\nfrom os import listdir\nfrom matplotlib import image\nfrom PIL import Image, ImageEnhance, ImageOps\nimport math\nimport random\nimport pdb\nfrom autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-21T12:45:34.471016Z","iopub.execute_input":"2021-05-21T12:45:34.471378Z","iopub.status.idle":"2021-05-21T12:45:40.033829Z","shell.execute_reply.started":"2021-05-21T12:45:34.471337Z","shell.execute_reply":"2021-05-21T12:45:40.033000Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#create func for different image net policy in 16 images\ndef show_sixteen(images, titles=0):\n    f, axarr = plt.subplots(4, 4, figsize=(15, 15), gridspec_kw={\"wspace\": 0, \"hspace\": 0})\n    for idx, ax in enumerate(f.axes):\n        ax.imshow(images[idx])\n        ax.axis(\"off\")\n        if titles: ax.set_title(titles[idx])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:45:40.035338Z","iopub.execute_input":"2021-05-21T12:45:40.035649Z","iopub.status.idle":"2021-05-21T12:45:40.092735Z","shell.execute_reply.started":"2021-05-21T12:45:40.035615Z","shell.execute_reply":"2021-05-21T12:45:40.091801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path leading to training images\ntraining_path = '../input/siim-isic-melanoma-classification/jpeg/train/' \n#generate a list of image names\ntraining_image_names = [name for name in os.listdir(training_path)]\n\n#testing the image loading and preporcessing\ntest_image = io.imread(training_path+training_image_names[2])\ntest_image = resize(test_image, (256, 256))\ntest_image = rgb2gray(test_image)\n\n#prepare the dataset images for augmentation, images need to be added to list then the the amount of images augmented will be = datasize\ndata_size = 5\n\ntraining_images = list()\ncount = 0\nfor filename in listdir('../input/siim-isic-melanoma-classification/jpeg/train/'):\n    #count for break\n    count = count + 1\n    print(count)\n    #add images to list\n    img_data = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/' + filename)\n    training_images.append(img_data)\n    #augment each image in list\n    policy = ImageNetPolicy()\n    for x in range(8) : \n        #add augmented images to list\n        training_images.append(policy(img_data))    \n    if count == data_size:\n        break\n        \n        \nprint(len(training_images))\n#convert all images to numpy array\nfor i in range(0,len(training_images)):\n        img_data = asarray(img_data) \n#convert list to array\ntraining_images = np.array(training_images) \n\n#show images to compare augmentations \nimg = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0015719.jpg')\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\nax1.imshow(img)\nimg2 = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0052212.jpg')\nax2.imshow(img2)\nplt.show()\n\nplt.imshow(test_image, cmap=plt.cm.gray)\ntest_image.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:47:26.179317Z","iopub.execute_input":"2021-05-21T12:47:26.179691Z","iopub.status.idle":"2021-05-21T12:47:31.295825Z","shell.execute_reply.started":"2021-05-21T12:47:26.179658Z","shell.execute_reply":"2021-05-21T12:47:31.293928Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1\n2\n3\n4\n5\n45\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-f41b63242c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#show images to compare augmentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'"],"ename":"TypeError","evalue":"int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'","output_type":"error"}]},{"cell_type":"code","source":"#create func for different image net policy in 16 images\ndef show_sixteen(images, titles=0):\n    f, axarr = plt.subplots(4, 4, figsize=(15, 15), gridspec_kw={\"wspace\": 0, \"hspace\": 0})\n    for idx, ax in enumerate(f.axes):\n        ax.imshow(images[idx])\n        ax.axis(\"off\")\n        if titles: ax.set_title(titles[idx])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:20.063134Z","iopub.execute_input":"2021-05-21T10:51:20.063592Z","iopub.status.idle":"2021-05-21T10:51:20.346151Z","shell.execute_reply.started":"2021-05-21T10:51:20.063544Z","shell.execute_reply":"2021-05-21T10:51:20.344776Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#load training csv\ntraining_labels = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv', sep=',')\n\n#the train.csv holds more information than we need, thus we extract only the needed columns\ntraining_labels = training_labels[['image_name', 'target']]\n\n# the targets are: 0 = benign, 1 = malignant\n#training labels that have a target of 0\ntraining_labels_0 = pd.DataFrame(training_labels.loc[training_labels['target'] == 0])\n#training labels that have a target of 1 \ntraining_labels_1 = pd.DataFrame(training_labels.loc[training_labels['target'] == 1])\n \n#in advance turn both pandas dataframes to numpy arrays, as we need to reshape their values later (a numpy function)\n#and because the resnet model only accepts numpy arrays as inputs\ntraining_labels_0 = np.asarray(training_labels_0)\ntraining_labels_1 = np.asarray(training_labels_1)\n\n#the structures of both numpy arrays are as follows:\n#training_labels_# [index of the image][0 = name of the image, 1 = the target]\n\nprint(\"labels with a target of 0:\",len(training_labels_0))\nprint(\"labels with a target of 1:\",len(training_labels_1))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:20.351349Z","iopub.execute_input":"2021-05-21T10:51:20.351744Z","iopub.status.idle":"2021-05-21T10:51:20.683454Z","shell.execute_reply.started":"2021-05-21T10:51:20.351712Z","shell.execute_reply":"2021-05-21T10:51:20.682124Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"labels with a target of 0: 32542\nlabels with a target of 1: 584\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#prepare numpy arrays, where the loaded images and labels will be stored\ntraining_images = np.zeros((data_size, 256, 256, 1))\ntraining_labels = np.zeros((data_size))\n\n#first store the images, with a target of 1\nfor i in range(0, len(training_labels_1)):\n    #load an image\n    image = io.imread(training_path+training_labels_1[i][0]+'.jpg')\n    #resizing...\n    image = resize(image, (256,256))\n    #making the image grayscale...\n    image = rgb2gray(image)\n    #normalising the values...\n    image /= 255\n    #reshaping, because the model expects an input shape of (x,y,z)\n    image = np.reshape(image, (256,256,1))\n    \n    #storing the image\n    training_images[i] = image\n    \n    #storing the target label\n    training_labels[i] = training_labels_1[i][1]\n    \n    if(i%200==0):\n        #simple way of informing about the progress\n        print(i, training_labels_1[i][0], \"uploaded\")\n        \n#same exact steps are applied to images, with a target of 0\nfor i in range(len(training_labels_1), data_size):\n    image = io.imread(training_path+training_labels_0[i][0]+'.jpg')\n    image = resize(image, (256,256))\n    image = rgb2gray(image)\n    image /= 255\n    image = np.reshape(image, (256,256,1))\n    \n    training_images[i] = image\n    training_labels[i] = training_labels_0[i][1]\n    if(i%200==0):\n        print(i ,training_labels_0[i][0], \"uploaded\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:20.685696Z","iopub.execute_input":"2021-05-21T10:51:20.686207Z","iopub.status.idle":"2021-05-21T10:51:21.265718Z","shell.execute_reply.started":"2021-05-21T10:51:20.686153Z","shell.execute_reply":"2021-05-21T10:51:21.263751Z"},"trusted":true},"execution_count":48,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-cef9b6b3c5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#prepare numpy arrays, where the loaded images and labels will be stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#first store the images, with a target of 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'"],"ename":"TypeError","evalue":"int() argument must be a string, a bytes-like object or a number, not 'JpegImageFile'","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(training_images.shape)\nprint(training_labels.shape)\nfrom sklearn.model_selection import train_test_split\n    \n    training_images[i] = image\n#split the data into training and testing\nx_train, x_test, y_train, y_test = train_test_split(training_images, training_labels, train_size=0.8, random_state=42)\n\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:21.267772Z","iopub.status.idle":"2021-05-21T10:51:21.268779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels[np.where(training_labels==0)].shape","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:21.271003Z","iopub.status.idle":"2021-05-21T10:51:21.271969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#The resnet model. For some reason the amount of classes in our database is 1\n#No weights, because imagenet is not useful for our purpose and i'm not aware of other weights we can use\n#The input shape follows the shape of the images\n#Sigmoid, because our classes range from 0 and 1 and it's recommended for binary categorization\nmodel = ResNet50(classes=1, weights=None, input_shape=(256,256,1), classifier_activation='sigmoid')\n\n#Binary crossentropy because our classes range from 0 and 1\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:21.273916Z","iopub.status.idle":"2021-05-21T10:51:21.274872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#batch_size of 8 for no particular reason. Batch size of 16 caused an error, internet said it's because batch size is too big\n#10 epochs, because the model is very deep and takes a very long time to train\nmodel.fit(x_train,y_train, batch_size=8, epochs=10, validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:21.276723Z","iopub.status.idle":"2021-05-21T10:51:21.277722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use this to load all of the images\ndata_size = 100\ntraining_images = np.zeros((data_size,256,256,1))\nfor index, imageName in enumerate(training_image_names[0:data_size]):\n    image = io.imread(trainingPath+imageName)\n    image = resize(image, (256, 256))\n    image = rgb2gray(image)\n    image /= 255\n    image = np.reshape(image, (256,256,1))\n    training_images[index] = image\n    if(index % (data_size//4) == 0):\n        print(index, imageName, \"inserted\")\n\n        \ntraining_labels = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv', sep=',')\n# 0 = benign, 1 = malignant\ntraining_labels = np.asarray(training_labels['target'])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T10:51:21.279465Z","iopub.status.idle":"2021-05-21T10:51:21.280369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}