{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import PIL\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os, os.path\n\nfrom keras.applications import ResNet50\n\nimport matplotlib.pyplot as plt\n\n#image preprocessing libraries\nimport skimage\nfrom skimage import io\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\n\n#import needed for augmentation\n%reload_ext autoreload\n%autoreload 2\n\nfrom os import listdir\nfrom matplotlib import image\nfrom PIL import Image, ImageEnhance, ImageOps\nimport math\nimport random\nimport pdb\nfrom autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T22:54:50.558073Z","iopub.execute_input":"2021-05-20T22:54:50.558502Z","iopub.status.idle":"2021-05-20T22:54:50.689035Z","shell.execute_reply.started":"2021-05-20T22:54:50.558466Z","shell.execute_reply":"2021-05-20T22:54:50.688318Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#create func for different image net policy in 16 images\ndef show_sixteen(images, titles=0):\n    f, axarr = plt.subplots(4, 4, figsize=(15, 15), gridspec_kw={\"wspace\": 0, \"hspace\": 0})\n    for idx, ax in enumerate(f.axes):\n        ax.imshow(images[idx])\n        ax.axis(\"off\")\n        if titles: ax.set_title(titles[idx])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T22:54:55.601412Z","iopub.execute_input":"2021-05-20T22:54:55.601756Z","iopub.status.idle":"2021-05-20T22:54:55.708940Z","shell.execute_reply.started":"2021-05-20T22:54:55.601725Z","shell.execute_reply":"2021-05-20T22:54:55.707692Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#path leading to training images\ntraining_path = '../input/siim-isic-melanoma-classification/jpeg/train/' \n#generate a list of image names\ntraining_image_names = [name for name in os.listdir(training_path)]\n\n#testing the image loading and preporcessing\ntest_image = io.imread(training_path+training_image_names[2])\ntest_image = resize(test_image, (256, 256))\ntest_image = rgb2gray(test_image)\n\n#prepare the dataset images for augmentation, images need to be added to list then the the amount of images augmented will be = datasize\ndata_size = 50\ntraining_images = list()\ncount = 0\nfor filename in listdir('../input/siim-isic-melanoma-classification/jpeg/train/'):\n    count = count + 1\n    print(count)\n    img_data = image.imread('../input/siim-isic-melanoma-classification/jpeg/train/' + filename)\n    training_images.append(img_data)\n    #augment each image in data size range\n    policy = ImageNetPolicy()\n    for i in range(data_size):\n        current_image = training_images.open(img_data)\n        for x in range(8): \n            training_images.append(policy(current_image))\n    show_sixteen(traning_images(1))\n    \n    if count == 50:\n        break\n\n#show images to compare augmentations \nimg = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0015719.jpg')\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\nax1.imshow(img)\nimg2 = Image.open('../input/siim-isic-melanoma-classification/jpeg/train/ISIC_0052212.jpg')\nax2.imshow(img2)\nplt.show()\n\n\nplt.imshow(test_image, cmap=plt.cm.gray)\ntest_image.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T23:09:20.226635Z","iopub.execute_input":"2021-05-20T23:09:20.226979Z","iopub.status.idle":"2021-05-20T23:09:20.845320Z","shell.execute_reply.started":"2021-05-20T23:09:20.226946Z","shell.execute_reply":"2021-05-20T23:09:20.844024Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-1f971db351c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#augment each image in data size range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageNetPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcurrent_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"#create func for different image net policy in 16 images\ndef show_sixteen(images, titles=0):\n    f, axarr = plt.subplots(4, 4, figsize=(15, 15), gridspec_kw={\"wspace\": 0, \"hspace\": 0})\n    for idx, ax in enumerate(f.axes):\n        ax.imshow(images[idx])\n        ax.axis(\"off\")\n        if titles: ax.set_title(titles[idx])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:33:46.809767Z","iopub.execute_input":"2021-05-20T21:33:46.810100Z","iopub.status.idle":"2021-05-20T21:33:47.000795Z","shell.execute_reply.started":"2021-05-20T21:33:46.810069Z","shell.execute_reply":"2021-05-20T21:33:46.999719Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#load training csv\ntraining_labels = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv', sep=',')\n\n#the train.csv holds more information than we need, thus we extract only the needed columns\ntraining_labels = training_labels[['image_name', 'target']]\n\n# the targets are: 0 = benign, 1 = malignant\n#training labels that have a target of 0\ntraining_labels_0 = pd.DataFrame(training_labels.loc[training_labels['target'] == 0])\n#training labels that have a target of 1 \ntraining_labels_1 = pd.DataFrame(training_labels.loc[training_labels['target'] == 1])\n \n#in advance turn both pandas dataframes to numpy arrays, as we need to reshape their values later (a numpy function)\n#and because the resnet model only accepts numpy arrays as inputs\ntraining_labels_0 = np.asarray(training_labels_0)\ntraining_labels_1 = np.asarray(training_labels_1)\n\n#the structures of both numpy arrays are as follows:\n#training_labels_# [index of the image][0 = name of the image, 1 = the target]\n\nprint(\"labels with a target of 0:\",len(training_labels_0))\nprint(\"labels with a target of 1:\",len(training_labels_1))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.145006Z","iopub.status.idle":"2021-05-20T21:07:37.145700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random data size\ndata_size = 2000\n\n#prepare numpy arrays, where the loaded images and labels will be stored\ntraining_images = np.zeros((data_size, 256, 256, 1))\ntraining_labels = np.zeros((data_size))\n\n#first store the images, with a target of 1\nfor i in range(0, len(training_labels_1)):\n    #load an image\n    image = io.imread(training_path+training_labels_1[i][0]+'.jpg')\n    #resizing...\n    image = resize(image, (256,256))\n    #making the image grayscale...\n    image = rgb2gray(image)\n    #normalising the values...\n    image /= 255\n    #reshaping, because the model expects an input shape of (x,y,z)\n    image = np.reshape(image, (256,256,1))\n    \n    #storing the image\n    training_images[i] = image\n    #storing the target label\n    training_labels[i] = training_labels_1[i][1]\n    \n    if(i%200==0):\n        #simple way of informing about the progress\n        print(i, training_labels_1[i][0], \"uploaded\")\n        \n#same exact steps are applied to images, with a target of 0\nfor i in range(len(training_labels_1), data_size):\n    image = io.imread(training_path+training_labels_0[i][0]+'.jpg')\n    image = resize(image, (256,256))\n    image = rgb2gray(image)\n    image /= 255\n    image = np.reshape(image, (256,256,1))\n    \n    training_images[i] = image\n    training_labels[i] = training_labels_0[i][1]\n    if(i%200==0):\n        print(i ,training_labels_0[i][0], \"uploaded\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:29:45.090275Z","iopub.execute_input":"2021-05-20T21:29:45.090691Z","iopub.status.idle":"2021-05-20T21:29:52.559387Z","shell.execute_reply.started":"2021-05-20T21:29:45.090656Z","shell.execute_reply":"2021-05-20T21:29:52.556985Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ee5a0d8cd4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mshow_sixteen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/autoaugment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mpolicy_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/autoaugment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagnitude1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagnitude2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/autoaugment.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(img, magnitude)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 1 + magnitude * random.choice([-1, 1])),\n\u001b[1;32m    218\u001b[0m             \u001b[0;34m\"autocontrast\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocontrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;34m\"equalize\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0;34m\"invert\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         }\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36mequalize\u001b[0;34m(image, mask)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \"\"\"\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'mode'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'mode'","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(training_images.shape)\nprint(training_labels.shape)\nfrom sklearn.model_selection import train_test_split\n#split the data into training and testing\nx_train, x_test, y_train, y_test = train_test_split(training_images, training_labels, train_size=0.8, random_state=42)\n\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.149137Z","iopub.status.idle":"2021-05-20T21:07:37.149838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels[np.where(training_labels==0)].shape","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.151264Z","iopub.status.idle":"2021-05-20T21:07:37.152085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#The resnet model. For some reason the amount of classes in our database is 1\n#No weights, because imagenet is not useful for our purpose and i'm not aware of other weights we can use\n#The input shape follows the shape of the images\n#Sigmoid, because our classes range from 0 and 1 and it's recommended for binary categorization\nmodel = ResNet50(classes=1, weights=None, input_shape=(256,256,1), classifier_activation='sigmoid')\n\n#Binary crossentropy because our classes range from 0 and 1\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.153892Z","iopub.status.idle":"2021-05-20T21:07:37.154623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#batch_size of 8 for no particular reason. Batch size of 16 caused an error, internet said it's because batch size is too big\n#10 epochs, because the model is very deep and takes a very long time to train\nmodel.fit(x_train,y_train, batch_size=8, epochs=10, validation_data=(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.155879Z","iopub.status.idle":"2021-05-20T21:07:37.156717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use this to load all of the images\ndata_size = 100\ntraining_images = np.zeros((data_size,256,256,1))\nfor index, imageName in enumerate(training_image_names[0:data_size]):\n    image = io.imread(trainingPath+imageName)\n    image = resize(image, (256, 256))\n    image = rgb2gray(image)\n    image /= 255\n    image = np.reshape(image, (256,256,1))\n    training_images[index] = image\n    if(index % (data_size//4) == 0):\n        print(index, imageName, \"inserted\")\n\n        \ntraining_labels = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv', sep=',')\n# 0 = benign, 1 = malignant\ntraining_labels = np.asarray(training_labels['target'])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-20T21:07:37.157983Z","iopub.status.idle":"2021-05-20T21:07:37.158807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}